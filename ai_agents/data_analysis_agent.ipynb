{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:03:21.797762Z",
     "start_time": "2025-04-05T21:03:19.062300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install llama-index llama-index-embeddings-openai qdrant-client llama-index-vector-stores-qdrant llama-index llama-index-llms-openai llama-index-vector-stores-faiss faiss-cpu llama-index-llms-anthropic tavily-python"
   ],
   "id": "b86314a8349ff81c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:03:21.915971Z",
     "start_time": "2025-04-05T21:03:21.884404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(r\"C:\\Users\\anteb\\PycharmProjects\\JupyterProject\\.env\")\n",
    "nest_asyncio.apply()\n",
    "\n",
    "CO_API_KEY = os.environ.get('CO_API_KEY') or getpass(\"Enter CO_API_KEY: \")\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or getpass(\"Enter OPENAI_API_KEY: \")\n",
    "QDRANT_URL = os.environ.get('QDRANT_URL') or getpass(\"Enter QDRANT_URL: \")\n",
    "QDRANT_API_KEY = os.environ.get('QDRANT_API_KEY') or getpass(\"Enter QDRANT_API_KEY: \")"
   ],
   "id": "77c4f62c96aa4ba6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:03:26.103372Z",
     "start_time": "2025-04-05T21:03:21.924382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from llama_index.core.workflow import Context\n",
    "import asyncio\n",
    "from llama_index.core.workflow import Workflow, Context, StartEvent, step\n",
    "\n",
    "from ai_agents.agents import data_prep_agent\n",
    "from events.events import DataLoadedEvent, InputRequiredEvent, DataPreparedEvent, HumanResponseEvent\n",
    "\n"
   ],
   "id": "beb09136c8eac474",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9cb817879d596293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:03:26.158113Z",
     "start_time": "2025-04-05T21:03:26.144271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "async def load_csv(ctx: Context, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV file into a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        print(f\"Successfully loaded {filename} with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "async def analyze_data_quality(ctx: Context, dataframe: pd.DataFrame) -> dict:\n",
    "    \"\"\"Analyze the quality of data in a DataFrame.\"\"\"\n",
    "    if dataframe is None:\n",
    "        return {\"error\": \"No dataframe provided\"}\n",
    "\n",
    "    quality_report = {\n",
    "        \"missing_values\": {},\n",
    "        \"data_types\": {},\n",
    "        \"unique_values\": {},\n",
    "        \"statistics\": {}\n",
    "    }\n",
    "\n",
    "    # Check for missing values\n",
    "    missing = dataframe.isnull().sum()\n",
    "    quality_report[\"missing_values\"] = {col: int(count) for col, count in missing.items() if count > 0}\n",
    "\n",
    "    # Check data types\n",
    "    quality_report[\"data_types\"] = {col: str(dtype) for col, dtype in dataframe.dtypes.items()}\n",
    "\n",
    "    # Check unique values for categorical columns\n",
    "    for col in dataframe.select_dtypes(include=['object', 'category']).columns:\n",
    "        if len(dataframe[col].unique()) < 10:  # Only for columns with few unique values\n",
    "            quality_report[\"unique_values\"][col] = dataframe[col].value_counts().to_dict()\n",
    "\n",
    "    # Basic statistics for numeric columns\n",
    "    for col in dataframe.select_dtypes(include=['number']).columns:\n",
    "        quality_report[\"statistics\"][col] = {\n",
    "            \"min\": float(dataframe[col].min()),\n",
    "            \"max\": float(dataframe[col].max()),\n",
    "            \"mean\": float(dataframe[col].mean()),\n",
    "            \"median\": float(dataframe[col].median()),\n",
    "            \"std\": float(dataframe[col].std())\n",
    "        }\n",
    "\n",
    "    return quality_report\n",
    "\n",
    "\n",
    "async def clean_data(ctx: Context, dataframe: pd.DataFrame, cleaning_actions: dict) -> tuple:\n",
    "    \"\"\"Clean a dataframe based on specified cleaning actions.\"\"\"\n",
    "    if dataframe is None:\n",
    "        return None, {\"error\": \"No dataframe provided\"}\n",
    "\n",
    "    df = dataframe.copy()\n",
    "    cleaning_summary = {}\n",
    "\n",
    "    # Handle missing values\n",
    "    if \"handle_missing\" in cleaning_actions:\n",
    "        for col, action in cleaning_actions[\"handle_missing\"].items():\n",
    "            if action == \"drop\":\n",
    "                before_count = len(df)\n",
    "                df = df.dropna(subset=[col])\n",
    "                after_count = len(df)\n",
    "                cleaning_summary[f\"dropped_rows_{col}\"] = before_count - after_count\n",
    "            elif action == \"mean\":\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    df[col] = df[col].fillna(df[col].mean())\n",
    "                    cleaning_summary[f\"filled_mean_{col}\"] = int(dataframe[col].isnull().sum())\n",
    "            elif action == \"median\":\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    df[col] = df[col].fillna(df[col].median())\n",
    "                    cleaning_summary[f\"filled_median_{col}\"] = int(dataframe[col].isnull().sum())\n",
    "            elif action == \"mode\":\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "                cleaning_summary[f\"filled_mode_{col}\"] = int(dataframe[col].isnull().sum())\n",
    "            elif action == \"zero\":\n",
    "                df[col] = df[col].fillna(0)\n",
    "                cleaning_summary[f\"filled_zero_{col}\"] = int(dataframe[col].isnull().sum())\n",
    "\n",
    "    # Convert data types\n",
    "    if \"convert_types\" in cleaning_actions:\n",
    "        for col, new_type in cleaning_actions[\"convert_types\"].items():\n",
    "            try:\n",
    "                df[col] = df[col].astype(new_type)\n",
    "                cleaning_summary[f\"converted_{col}\"] = new_type\n",
    "            except:\n",
    "                cleaning_summary[f\"failed_convert_{col}\"] = new_type\n",
    "\n",
    "    # Remove outliers\n",
    "    if \"remove_outliers\" in cleaning_actions:\n",
    "        for col in cleaning_actions[\"remove_outliers\"]:\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "                before_count = len(df)\n",
    "                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "                after_count = len(df)\n",
    "                cleaning_summary[f\"removed_outliers_{col}\"] = before_count - after_count\n",
    "\n",
    "    # Rename columns\n",
    "    if \"rename_columns\" in cleaning_actions:\n",
    "        df = df.rename(columns=cleaning_actions[\"rename_columns\"])\n",
    "        cleaning_summary[\"renamed_columns\"] = cleaning_actions[\"rename_columns\"]\n",
    "\n",
    "    # Drop columns\n",
    "    if \"drop_columns\" in cleaning_actions:\n",
    "        df = df.drop(columns=cleaning_actions[\"drop_columns\"])\n",
    "        cleaning_summary[\"dropped_columns\"] = cleaning_actions[\"drop_columns\"]\n",
    "\n",
    "    return df, cleaning_summary"
   ],
   "id": "f5fb21ba4f9903b5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "816129a41a3248c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:03:27.983782Z",
     "start_time": "2025-04-05T21:03:27.973114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ai_agents.data_preparation_workflow import DataPreparationWorkflow\n",
    "\n",
    "\n",
    "async def run_data_preparation_pipeline(filename):\n",
    "    \"\"\"Run the data preparation pipeline with human-in-the-loop interactions.\"\"\"\n",
    "    # Initialize the workflow\n",
    "    workflow = DataPreparationWorkflow(timeout=300)\n",
    "\n",
    "    # Start the workflow\n",
    "    handler = workflow.run(filename=filename)\n",
    "\n",
    "    # Handle events\n",
    "    async for event in handler.stream_events():\n",
    "        if isinstance(event, InputRequiredEvent):\n",
    "            # Display question to the user\n",
    "            print(f\"\\n[QUESTION] {event.question}\")\n",
    "\n",
    "            # Display context if available\n",
    "            if event.context:\n",
    "                print(\"\\nContext:\")\n",
    "                for key, value in event.context.items():\n",
    "                    print(f\"- {key}: {value}\")\n",
    "\n",
    "            # Get user response\n",
    "            response = input(\"\\nYour response: \")\n",
    "\n",
    "            # Send response back to the workflow\n",
    "            handler.ctx.send_event(\n",
    "                HumanResponseEvent(\n",
    "                    response=response,\n",
    "                    step_name=event.step_name\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Get final result\n",
    "    result = await handler\n",
    "    print(\"\\nWorkflow completed!\")\n",
    "    print(f\"Data preparation summary: {result.get('cleaning_summary', {})}\")\n",
    "\n",
    "    # Check if we have a dataframe to print shape\n",
    "    prepared_df = await handler.ctx.get(\"prepared_dataframe\")\n",
    "    if prepared_df is not None:\n",
    "        print(f\"Processed dataframe shape: {prepared_df.shape}\")\n",
    "\n",
    "    return result"
   ],
   "id": "c548a68b086fcc68",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:03:29.922753Z",
     "start_time": "2025-04-05T21:03:28.719788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply nest_asyncio to run async code in notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the data preparation pipeline\n",
    "result = asyncio.run(run_data_preparation_pipeline(r\"/data/Commute_Times_V1.csv\"))\n",
    "\n",
    "# Examine the prepared data\n",
    "if result:\n",
    "    df = result.dataframe\n",
    "    print(\"\\nFirst 5 rows of prepared data:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\nData summary:\")\n",
    "    display(df.describe())"
   ],
   "id": "5689ea4f4e6bbd4e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-6858db605965', bound_args=<BoundArgumen...mes_V1.csv'})>, instance=<ai_agents.da...002886441B680>, context=<_contextvars...00288639C3440>)(<WorkflowHand...async_chat'\")>) at C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:274\n",
      "handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-6858db605965', bound_args=<BoundArgumen...mes_V1.csv'})>, instance=<ai_agents.da...002886441B680>, context=<_contextvars...00288639C3440>)(<WorkflowHand...async_chat'\")>) at C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:274>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py\", line 500, in _step_worker\n",
      "    new_ev = await instrumented_step(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py\", line 368, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\PycharmProjects\\DataAnalysisPipelineAgent\\ai_agents\\data_preparation_workflow.py\", line 23, in load_data\n",
      "    load_response = await data_prep_agent.async_chat(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\pydantic\\main.py\", line 891, in __getattr__\n",
      "    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\n",
      "AttributeError: 'FunctionAgent' object has no attribute 'async_chat'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py\", line 286, in handle_future_result\n",
      "    raise exception\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\asyncio\\tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\AppData\\Local\\Temp\\ipykernel_18184\\1862453467.py\", line 36, in run_data_preparation_pipeline\n",
      "    result = await handler\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\asyncio\\futures.py\", line 294, in __await__\n",
      "    return self.result()  # May raise too.\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py\", line 394, in _run_workflow\n",
      "    raise exception_raised\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\asyncio\\tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py\", line 508, in _step_worker\n",
      "    raise WorkflowRuntimeError(\n",
      "llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'load_data': 'FunctionAgent' object has no attribute 'async_chat'\n"
     ]
    },
    {
     "ename": "WorkflowRuntimeError",
     "evalue": "Error in step 'load_data': 'FunctionAgent' object has no attribute 'async_chat'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py:500\u001B[0m, in \u001B[0;36mContext._step_worker\u001B[1;34m(self, name, step, config, stepwise, verbose, checkpoint_callback, run_id, service_manager, dispatcher)\u001B[0m\n\u001B[0;32m    499\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 500\u001B[0m     new_ev \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m instrumented_step(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    501\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mclear()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:368\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.async_wrapper\u001B[1;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[0;32m    367\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 368\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalysisPipelineAgent\\ai_agents\\data_preparation_workflow.py:23\u001B[0m, in \u001B[0;36mDataPreparationWorkflow.load_data\u001B[1;34m(self, ctx, ev)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Use the agent to load the file\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Replace astream_chat with async_chat\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m load_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m data_prep_agent\u001B[38;5;241m.\u001B[39masync_chat(\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease load the CSV file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mev\u001B[38;5;241m.\u001B[39mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and provide a brief summary of its contents.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     25\u001B[0m )\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Since async_chat doesn't stream, we can directly get the response\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:891\u001B[0m, in \u001B[0;36mBaseModel.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    889\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    890\u001B[0m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[1;32m--> 891\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'FunctionAgent' object has no attribute 'async_chat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mWorkflowRuntimeError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m nest_asyncio\u001B[38;5;241m.\u001B[39mapply()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Run the data preparation pipeline\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m result \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mrun(run_data_preparation_pipeline(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/data/Commute_Times_V1.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Examine the prepared data\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:30\u001B[0m, in \u001B[0;36m_patch_asyncio.<locals>.run\u001B[1;34m(main, debug)\u001B[0m\n\u001B[0;32m     28\u001B[0m task \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mensure_future(main)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mrun_until_complete(task)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m task\u001B[38;5;241m.\u001B[39mdone():\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:98\u001B[0m, in \u001B[0;36m_patch_loop.<locals>.run_until_complete\u001B[1;34m(self, future)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m f\u001B[38;5;241m.\u001B[39mdone():\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m     97\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvent loop stopped before Future completed.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 98\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39mresult()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\asyncio\\futures.py:203\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__log_traceback \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 203\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\u001B[38;5;241m.\u001B[39mwith_traceback(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception_tb)\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\asyncio\\tasks.py:314\u001B[0m, in \u001B[0;36mTask.__step_run_and_handle_result\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    312\u001B[0m         \u001B[38;5;66;03m# We use the `send` method directly, because coroutines\u001B[39;00m\n\u001B[0;32m    313\u001B[0m         \u001B[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001B[39;00m\n\u001B[1;32m--> 314\u001B[0m         result \u001B[38;5;241m=\u001B[39m coro\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    316\u001B[0m         result \u001B[38;5;241m=\u001B[39m coro\u001B[38;5;241m.\u001B[39mthrow(exc)\n",
      "Cell \u001B[1;32mIn[8], line 36\u001B[0m, in \u001B[0;36mrun_data_preparation_pipeline\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m     28\u001B[0m         handler\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39msend_event(\n\u001B[0;32m     29\u001B[0m             HumanResponseEvent(\n\u001B[0;32m     30\u001B[0m                 response\u001B[38;5;241m=\u001B[39mresponse,\n\u001B[0;32m     31\u001B[0m                 step_name\u001B[38;5;241m=\u001B[39mevent\u001B[38;5;241m.\u001B[39mstep_name\n\u001B[0;32m     32\u001B[0m             )\n\u001B[0;32m     33\u001B[0m         )\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Get final result\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m handler\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mWorkflow completed!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData preparation summary: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcleaning_summary\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m{})\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\asyncio\\futures.py:294\u001B[0m, in \u001B[0;36mFuture.__await__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone():\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mawait wasn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt used with future\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 294\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\asyncio\\futures.py:203\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__log_traceback \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 203\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\u001B[38;5;241m.\u001B[39mwith_traceback(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception_tb)\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py:394\u001B[0m, in \u001B[0;36mWorkflow.run.<locals>._run_workflow\u001B[1;34m()\u001B[0m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exception_raised:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;66;03m# cancel the stream\u001B[39;00m\n\u001B[0;32m    392\u001B[0m     ctx\u001B[38;5;241m.\u001B[39mwrite_event_to_stream(StopEvent())\n\u001B[1;32m--> 394\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exception_raised\n\u001B[0;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m we_done:\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;66;03m# cancel the stream\u001B[39;00m\n\u001B[0;32m    398\u001B[0m     ctx\u001B[38;5;241m.\u001B[39mwrite_event_to_stream(StopEvent())\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\asyncio\\tasks.py:314\u001B[0m, in \u001B[0;36mTask.__step_run_and_handle_result\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    312\u001B[0m         \u001B[38;5;66;03m# We use the `send` method directly, because coroutines\u001B[39;00m\n\u001B[0;32m    313\u001B[0m         \u001B[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001B[39;00m\n\u001B[1;32m--> 314\u001B[0m         result \u001B[38;5;241m=\u001B[39m coro\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    316\u001B[0m         result \u001B[38;5;241m=\u001B[39m coro\u001B[38;5;241m.\u001B[39mthrow(exc)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py:508\u001B[0m, in \u001B[0;36mContext._step_worker\u001B[1;34m(self, name, step, config, stepwise, verbose, checkpoint_callback, run_id, service_manager, dispatcher)\u001B[0m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mretry_policy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 508\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m WorkflowRuntimeError(\n\u001B[0;32m    509\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError in step \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m!s}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    510\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    512\u001B[0m     delay \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mretry_policy\u001B[38;5;241m.\u001B[39mnext(\n\u001B[0;32m    513\u001B[0m         retry_start_at \u001B[38;5;241m+\u001B[39m time\u001B[38;5;241m.\u001B[39mtime(), attempts, e\n\u001B[0;32m    514\u001B[0m     )\n\u001B[0;32m    515\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m delay \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    516\u001B[0m         \u001B[38;5;66;03m# We're done retrying\u001B[39;00m\n",
      "\u001B[1;31mWorkflowRuntimeError\u001B[0m: Error in step 'load_data': 'FunctionAgent' object has no attribute 'async_chat'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "41d88eee2ebadc49",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
